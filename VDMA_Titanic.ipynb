{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VDMA Online-Workshop\n",
    "### KI-Projekte umsetzen - Vorgehensmodell zur Umsetzung\n",
    "\n",
    "<img src=\"images/Vorgehen.JPG\" alt=\"drawing\" width=\"550\"/>\n",
    "\n",
    "In diesem Workshop geht es darum, ein KI-Projekt, wie im **VDMA Leitfaden Künstliche Intelligenz** beschrieben, selbstständig umzusetzen. Für die Übung müssen nur Änderungen im folgenden Feld vorgenommen werden. Die Erklärung der einzelnen Parameter werden entlang des Beispielprojekts noch erklärt.\n",
    "\n",
    "<img src=\"images/Bearbeiten.jpg\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Entscheidungen bezüglich der Datenvorverbereitung\n",
    "Feature_Alleine = 0                         # \"Alleine\"-Features erzeugen (0=Nein, 1 = Ja)\n",
    "Feature_Titel = 0                           # \"Titel\"-Features erzeugen (0=Nein, 1=Ja)\n",
    "\n",
    "# Entscheidungen bezüglich des maschinellen Lernverfahrens\n",
    "Klassifizierer_Typ = 0                       # Eingesetztes maschinelles Lernverfahren (0: Entscheidungsbaum, 1: RandomForest)\n",
    "Parameter_Entscheidungsbaum_Tiefe = 2        # Einstellbarer Parameter bei Entscheidungsbaum (wenn Klassifizierer_Typ=0)\n",
    "Parameter_RandomForest_Tiefe = 2             # Einstellbarer Parameter bei RandomForest (wenn Klassifizierer_Typ=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritte:\n",
    "1. Lassen Sie den Code einmal mit den **Starteinstellungen** laufen (kein Feature Engineering, Entscheidungsbaum mit max. Tiefe 2) <br/>\n",
    "*Nach welchen Kriterien entscheidet das Modell? (siehe Phase 5)*\n",
    "<br/>\n",
    "\n",
    "2. Versuchen Sie  die Vorhersagegenauigkeit zu steigern, indem Sie die max. Tiefe (**Parameter_Entscheidungsbaum_Tiefe**) des Entscheidungsbaums auf 4 erhöhen. \\\n",
    "*Konnte die Vorhersagegenauigkeit auf den Testdaten erhöht werden?*\n",
    "<br/>\n",
    "\n",
    "3. Steigern Sie die max. Tiefe des Entscheidungsbaums auf 5. \\\n",
    "*Konnte die Vorhersagegenauigkeit weiter erhöht werden? Nach welchen Kriterien entscheidet das Modell hier?*\n",
    "<br/>\n",
    "\n",
    "4. Stellen Sie ein, dass im Rahmen der Datenvorbereitung ein zusätzliches Feature erzeugt wird, welches Informationen darüber enthält, ob eine Person alleine oder mit Verwandten an Board der Titanic war (**Feature_Alleine**). \\\n",
    "*Wie hat sich der Datensatz nach der Aufbereitung verändert? Konnte die Vorhersagegenauigkeit erhöht werden?*\n",
    "<br/>\n",
    "\n",
    "5. Stellen Sie zusätzlich ein, dass im Rahmen der Datenvorbereitung ein zusätzliches Feature erzeugt wird, welches Informationen zum Titel der Personen aus deren Namen ableitet (**Feature_Titel**). \\\n",
    "*Wie hat sich der Datensatz nach der Aufbereitung verändert? Konnte die Vorhersagegenauigkeit erhöht werden?*\n",
    "<br/>\n",
    "\n",
    "6. Nun konzentrieren wir uns nur noch auf das maschinelle Lernverfahren. Neben Entscheidungsbäumen existieren auch weitere maschinelle Lernverfahren wie RandomForest. Diese können oftmals komplexere Zusammenhänge erlernen, allerdings wird die Interpretation der gelernten Zusammenhänge auch schwieriger. Stellen Sie ein, dass RandomForest nun zur Vorhersage genutzt wird (**Klassifizierer_Typ**). \\\n",
    "*Wie hat sich die Vorhersagegenauigkeit verändert?*\n",
    "<br/>\n",
    "\n",
    "7. Versuchen Sie nun durch die Einstellung des Hyperparameters von RandomForest (**Parameter_RandomForest_Tiefe**) die Vorhersagegenauigkeit zu verbessern (Bereich von 2 bis 100). \\\n",
    "*Was ist der optimale Wert für \"RandomForest_Tiefe\"? Wie verändern sich die Vorhersagegenauigkeiten auf den Trainungsdaten und den Testdaten?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### Tipp: Wenn Sie Änderungen durchgeführt haben, können sie den Code über den folgenden Befehl ausführen:\n",
    "\n",
    "<img src=\"images/Jupyter.jpg\" alt=\"drawing\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "# Phase 1 – Das Fundament: Das gemeinsame Geschäfts- und Projektverständnis \n",
    "![](images/Titanic.jpg)\n",
    "<div style=\"text-align: right\"> Bildquelle: Pixabay </div>\n",
    "\n",
    "### Ausgangssituation\n",
    "Historiker wollen sich mit dem Leben der Überlebenden der Titanic-Katastrophe beschäftigen. Heute sind nurnoch Interviews mit Nachkommen der Überlebenden möglich und die Suche nach diesen Nachkommen erweist sich als extrem zeitaufwändig. Es existiert im Archiv ein Datensatz mit Überlebenden der Katastrophe, allerdings konnten hier keine Nachkommen gefunden werden. Es existiert auch eine weitere Liste, allerdings fehlen hier die Angaben, ob die Personen überlebt haben und die Historiker haben nicht die Zeit eine Recherche für jede Person auf der Liste durchzuführen.\n",
    "\n",
    "### Ziel\n",
    "Ihr Aufgabe besteht daher darin, eine KI-Anwendung zu entwickeln, welche auf Basis der zur Verfügung stehenden Daten zu jeder Person (Alter, Geschlecht, Klasse etc.) eine Prognose aufzustellt, ob diese Person überlebt hat. Mit Hilfe Ihrer KI-Anwendung wollen die Historiker nur Recherchen für Personen durchführen, welche vermutlich auch überlebt hatten.\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "# Phase 2 – Die tragenden Säulen: Das Technologie-, Prozess- und Datenverständnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken zur Bearbeitung von Daten\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# Bibliotheken um Daten zu Visualisieren\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Bibliotheken zum Maschinellen Lernen\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welche Daten stehen zur Verfügung?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden der Daten und Betrachtung der ersten 5 Zeilen\n",
    "Daten = pd.read_csv('./input/Titanic_Datensatz.csv')\n",
    "Daten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **PassagierID**: Eindeutige ID für jeden Passagier\n",
    "- **Lebendig**: Ob der Passagier überlebt hat oder nicht und der von uns vorhergesagte Wert (0=Nein, 1=Ja)\n",
    "- **Klasse**: Die Klasse des Tickets, das der Passagier gekauft hat (1=1. Klasse, 2=2. Klasse, 3=3. Klasse)\n",
    "- **Name**: Der Name des Passagiers\n",
    "- **Geschlecht**: Das Geschlecht des Passagiers\n",
    "- **Alter**: Das Alter des Passagiers in Jahren\n",
    "- **GeschwPartner**: Die Anzahl der Geschwister oder Ehepartner, die der Passagier an Bord der Titanic hatte\n",
    "- **ElterKind**: Die Anzahl der Eltern oder Kinder, die der Passagier an Bord der Titanic hatte\n",
    "- **Ticketnummer**: Die Ticketnummer des Passagiers\n",
    "- **Preis**: Der Ticketpreis, den der Fahrgast bezahlt hat\n",
    "- **Kabine**: Die Kabinennummer des Passagiers\n",
    "- **Hafen**: Der Hafen, in dem der Passagier eingestiegen ist (C=Cherbourg, Q=Queenstown, S=Southampton)\n",
    "\n",
    "### Gibt es Datenlücken oder häufige Ausreißer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Fehler.jpg\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Betrachtung der Zahlenwerte\n",
    "Daten.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Betrachtung der textuellen Werte\n",
    "Daten.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Was kann noch aus den Daten herausgelesen werden?\n",
    "Welchen Einfluss hat das Alter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Erstellung eines Diagramms mit der Altersverteilung bei Personen die überlebt haben bzw. nicht überlebt haben\n",
    "g = sns.FacetGrid(Daten, col='Lebendig')\n",
    "g.map(plt.hist, 'Alter', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welchen Einfluss haben die Klasse (1./2./3. Klasse) zusammen mit dem Alter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weitere Aufteilung des vorherigen Diagramms, nur dass hier auch zusätzlich die Klassen unterschieden werden\n",
    "grid = sns.FacetGrid(Daten, col='Lebendig', row='Klasse', size=2.2, aspect=1.6)\n",
    "grid.map(plt.hist, 'Alter', alpha=.5, bins=20)\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "# Phase 3 – Der Rohbau: Die Datenvorbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bereinigen der Daten\n",
    "Laut den Historikern lassen sich aus den Kabinenbezeichnungen und PassagierID keine Informationen ableiten. Sie haben zudem gesehen, dass diese bei den meisten Personen garnicht angegeben wurden. Auch die Ticketnummern wurden laut den Historikern zufällig erstellt und enthalten daher keine Informationen. Sie beschließen daher Ticketnummern, PassagierID und Kabinenbezeichnungen zu ignorieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Löschen der Spalten \"Ticketnummer\", \"PassagierID\" und \"Kabine\"\n",
    "Daten = Daten.drop(['Ticketnummer', 'PassagierID', 'Kabine'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leider fehlen im Datensatz bei manchen Personen die Angaben zum Alter. Sie beschließen daher bei den fehlenden Altersangaben den Alterdurchschnitt über alle Personen einzusetzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ersetzen aller fehlenden Altersangaben durch den Durchschnittswert\n",
    "Daten['Alter'].fillna(Daten['Alter'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch fehlen teilweise die Angaben zum Einstiegshafen der Personen, wobei hier der Hafen mit den meisten Passagierzugängen eingesetzt wird (Hafen S=Southampton)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ersetzen der fehlenden Hafenangaben durch den am häufigsten auftredenden Wert\n",
    "Daten['Hafen'].fillna(Daten['Hafen'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prüfen ob wirklich keine Datenlücken mehr vorhanden sind\n",
    "Daten.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Einstellung.jpg\" alt=\"drawing\"  width=\"80\" align=\"left\"/>\n",
    "\n",
    "<div style=\"position:relative;left:20px\"> Die Historiker nehmen an, dass die Gesamtzahl an Verwandten und Partnern an Board nicht so wichtig ist. Gerade beim betreten der Rettungsbote könnte allerdings entscheidend gewesen sein, ob man alleine war oder nicht. </div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wenn Feature_Alleine = 1 werden GeschwPartner und ElterKind konsolidiert und an ihrer Stelle eine Spalte \"Alleine\" eingefügt\n",
    "if Feature_Alleine == 1:\n",
    "    Daten['Familie'] = Daten['GeschwPartner'] + Daten['ElterKind']\n",
    "    Daten['Alleine'] = 0\n",
    "    Daten.loc[Daten['Familie'] == 0, 'Alleine'] = 1\n",
    "    Daten = Daten.drop(['Familie', 'GeschwPartner', 'ElterKind'], axis=1)\n",
    "    show = Daten[['Alleine', 'Lebendig']].groupby(['Alleine'], as_index=False).mean()\n",
    "    print(show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Einstellung.jpg\" alt=\"drawing\"  width=\"80\" align=\"left\"/>\n",
    "\n",
    "<div style=\"position:relative;left:20px\"> Die Historiker weisen Sie zudem darauf hin, dass in den Namen auch Titel enthalten sind. Sie vermuten, dass sich in den verschiedenen Titelbezeichnungen neben dem Geschlecht zusätzliche Informationen (z. B. Rang) verbergen. Sie extrahieren daher zunächst die Titel.</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wenn Feature_Titel = 1 werden in der Spalte \"Namen\" \n",
    "if Feature_Titel == 1:\n",
    "    Daten['Titel'] = Daten.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    #Gegenüberstellen von Titel und Geschlecht\n",
    "    show = pd.crosstab(Daten['Titel'], Daten['Geschlecht']) \n",
    "    print(show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es zeigt sich, dass viele unterschiedliche Titel in den Namen enthalten sind und diese auch Rückschlüsse zur Hierarchie (z. B. Master) ziehen lassen und bei Frauen die zusätzliche Information besitzen, ob diese verheiratet sind oder nicht (Miss=unverheiratet, Mrs=verheiratet). Sie beschließen daher, diese Informationen mitaufzunehmen und seltene Titelbezeichnungen zusammenzufassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Feature_Titel == 1:\n",
    "    Daten['Titel'] = Daten['Titel'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Selten')\n",
    "    Daten['Titel'] = Daten['Titel'].replace('Mlle', 'Miss')\n",
    "    Daten['Titel'] = Daten['Titel'].replace('Ms', 'Miss')\n",
    "    Daten['Titel'] = Daten['Titel'].replace('Mme', 'Mrs')\n",
    "    Daten['Titel'] = Daten['Titel'].fillna(0)\n",
    "    #Gegenüberstellen von Titel und Überlebenswahrscheinlichkeit rein auf Basis des Titels\n",
    "    show = Daten[['Titel', 'Lebendig']].groupby(['Titel'], as_index=False).mean()\n",
    "    print(show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da die meisten Lernalgorithmen mit einfachem Text nicht arbeiten können, werden die textuellen Werte zudem in Zahlenwerte umgewandelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Löschen der Spalte \"Namen\"\n",
    "Daten = Daten.drop(['Name'], axis=1)\n",
    "#Ersetzen von Mann/Frau mit 0/1\n",
    "Daten['Geschlecht'] = Daten['Geschlecht'].map( {'Frau': 1, 'Mann': 0} ).astype(int)\n",
    "#Aufteilung der restlichen textuellen Werte in einzelne Spalten (sog. One-Hot Encoding)\n",
    "Daten = pd.get_dummies(Daten, sparse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Aufbereiteter_Datensatz.jpg\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Der aufbereitete Datensatz sieht nun wiefolgt aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Daten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "# Phase 4 – Das Herzstück: Die Modellierung\n",
    "### Die aufbereiteten Daten werden zum Trainieren in einem maschinellen Lernverfahren eingesetzt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das trainierte Modell bzw. den Klassifizierer testen zu können. Wird der bestehende Datensatz in einen Trainingsdatensatz und einen Testdatensatz aufgeteilt. Auf dem Trainingsdatensatz wird der Klassifizierer erlernt und anschließend auf den neuen Daten im Testdatensatz evaluiert.\n",
    "<img src=\"images/Train_Test.jpg\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Einstellung.jpg\" alt=\"drawing\"  width=\"80\" align=\"left\"/>\n",
    "\n",
    "<div style=\"position:relative;left:20px\"> Hier wird entschieden, welches maschinelle Lernverfahren eingesetzt werden soll und wie dessen Hyperparameter eingestellt werden. Im Feld zur Bearbeitung können Sie wählen zwischen Entscheidungsbaum (Klassifizierer_Typ = 0) und RandomForest (Klassifizierer_Typ = 1) sowie deren einstellbaren Hyperparametern (Parameter_Entscheidungsbaum_Tiefe bzw. Parameter_RandomForest_Tiefe) </div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aufteilung der Daten die Spalten mit Features (X_Daten) und der Spalte mir der vorherzusagenen Werten (Y_Daten) \n",
    "X_Daten = Daten.drop(\"Lebendig\", axis=1)\n",
    "Y_Daten = Daten[\"Lebendig\"]\n",
    "\n",
    "#Um das Ergebnis testen zu können, werden nur 70% zum lernen verwendet (Train) und 30% zum testen beibehalten (Test) \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_Daten, Y_Daten, test_size=0.30, random_state=42)\n",
    "\n",
    "#Auswahl des maschinellen Lernverfahrens für den Klassifizierer\n",
    "if Klassifizierer_Typ == 0 :\n",
    "    Klassifizierer = DecisionTreeClassifier(max_depth=Parameter_Entscheidungsbaum_Tiefe, random_state = 42, min_samples_split = 0.1)\n",
    "elif  Klassifizierer_Typ == 1:\n",
    "    Klassifizierer = RandomForestClassifier(max_depth=Parameter_RandomForest_Tiefe, random_state = 42) #, min_samples_split = 0.1\n",
    "#Das eigentliche Trainieren des Modells\n",
    "Klassifizierer.fit(X_train, Y_train)\n",
    "\n",
    "#Berechnung der Vorhersagegenauigkeit auf den Trainings- und Testdaten\n",
    "Vorhersagegenauigkeit_train = round(Klassifizierer.score(X_train, Y_train) * 100, 2)\n",
    "Vorhersagegenauigkeit_test = round(Klassifizierer.score(X_test, Y_test) * 100, 2)\n",
    "print(\"Vorhersagegenauigkeit auf Trainingsdaten = \", Vorhersagegenauigkeit_train, \"%\\n Vorhersagegenauigkeit auf Testdaten =\", Vorhersagegenauigkeit_test, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Vergleich_Experimente.jpg\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laden der Datei mit vorherigen Experimenten\n",
    "Ergebnisse = pd.read_csv('./input/Ergebnisse.csv')\n",
    "\n",
    "#Erstellung einer neuen Zeile mit den eingestellten Parametern und den Ergebnissen\n",
    "if Klassifizierer_Typ == 0 :\n",
    "    Parameter = 'Entscheidungsbaum_Tiefe: ' + str(Parameter_Entscheidungsbaum_Tiefe)\n",
    "else :\n",
    "    Parameter = 'RandomForest_Tiefe: ' + str(Parameter_RandomForest_Tiefe)\n",
    "Neuer_Versuch = pd.DataFrame({'Feature_Alleine':Feature_Alleine, 'Feature_Titel':Feature_Titel, 'Klassifizierer_Typ':Klassifizierer_Typ, 'Parameter':Parameter, 'Vorhersagegenauigkeit_Train':str(Vorhersagegenauigkeit_train)+\" %\", 'Vorhersagegenauigkeit_Test': str(Vorhersagegenauigkeit_test)+\" %\"}, index=[0])\n",
    "Ergebnisse = [Ergebnisse, Neuer_Versuch]\n",
    "\n",
    "#Zusammenführung der vergangenen und der neuen Ergebnisse und speichern der aktualisierten Liste\n",
    "Ergebnisse = pd.concat(Ergebnisse)\n",
    "Ergebnisse.to_csv('./input/Ergebnisse.csv',index=False)\n",
    "Ergebnisse = pd.read_csv('./input/Ergebnisse.csv')\n",
    "Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ziel ist es, die Vorhersagegenauigkeit des Modells auf neuen, ungesehen Daten zu testen und die Genauigkeit hierfür (Vorhersagegenauigkeit_Test) zu erhöhen. Sollte die Vorhersagegenauigkeit auf den Trainingsdaten (Vorhersagegenauigkeit_Train) weitaus höher sein, scheinen hier Zusammenhänge gelernt zu werden, welche eigentlich nicht existieren (sog. Overfitting)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "# Phase 5 – Die Wertschöpfung: Die Auswertung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wie weit reduziert sich der Aufwand der Historiker? Wie hoch ist die Wahrscheinlichkeit, dass Nachkommen einer Person gesucht werden und es sich herausstellt, dass diese Person doch nicht überlebt hatte?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fehlerquote = round(100-Vorhersagegenauigkeit_test, 2)\n",
    "Personenzahl = 200\n",
    "Recherche_bisher = int(Personenzahl*62/100)\n",
    "Recherche_umsonst = int(Personenzahl*Fehlerquote/100)\n",
    "print(\"Die Wahrscheinlichkeit Aufwände in die Recherche bei falschen Personen durchzuführen ist\", Fehlerquote, \"%.\\n \\\n",
    "Laut den Historikern soll noch bei höchstens\",Personenzahl,\" weiteren Personen eine Recherche durchgeführt werden.\\n \\\n",
    "Bei zufälliger Auswahl wären hier ca. \",Recherche_bisher,\" Recherchen umsonst (da laut den Daten ca. 62 % nicht überlebt haben).\\n \\\n",
    "Mit dem Vorhersagemodell reduziert sich die Anzahl der nicht notwendig gewesenen Recherchen auf ca.\",Recherche_umsonst, \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nach welchen Kriterien werden im Modell die Entscheidungen getroffen? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(Klassifizierer.feature_importances_, index=X_train.columns)\n",
    "fig_importance = plt.figure(figsize=(15,10))\n",
    "fig_importance = feat_importances.nsmallest(20).plot(kind='barh', fontsize=10)\n",
    "fig_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Klassifizierer_Typ == 0:\n",
    "    fig_tree = plt.figure(figsize=(15,20))\n",
    "    fig_tree = plot_tree(Klassifizierer, feature_names=X_train.columns, class_names=['Verstorben', 'Überlebt'], filled=True, fontsize=10, proportion=True, rounded=True, precision=2, impurity=False)\n",
    "elif  Klassifizierer_Typ == 1:\n",
    "    print(\"Die Baumstruktur kann nur bei Entscheidungsbäumen angezeigt werden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "# Phase 6 – Die geschaffene Lösung: Bereitstellung\n",
    "### Die Historiker konnten bereits eine Liste von Personen ausfindig machen und möchten nun bei den  Personen Vorhersagen treffen, ob diese überlebt haben. Im unteren Feld können Sie sich auch eigene Personen erdenken und der Liste hinzufügen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Person für die Vorhersage selber definieren\n",
    "Person = {'PassagierID':[1310], 'Klasse':[1], 'Name':['Bukater, Rose DeWitt'], 'Geschlecht':['Frau'], 'Alter':[17] \\\n",
    "          , 'GeschwPartner':[0],'ElterKind':[2], 'Ticketnummer':['PC 17601'], 'Preis':[88.5], 'Kabine':['B12'], 'Hafen':['S']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden der neuen Daten\n",
    "personenliste_df = pd.read_csv('./input/Titanic_Personenliste.csv') \n",
    "personenliste_df = personenliste_df.append(pd.DataFrame(Person), ignore_index=True)\n",
    "personenliste_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Durchlaufen der Datenaufbereitung\n",
    "liste_df = personenliste_df\n",
    "liste_df = liste_df.drop(['Ticketnummer', 'PassagierID', 'Kabine'], axis=1)\n",
    "liste_df['Alter'].fillna(liste_df['Alter'].median(), inplace = True)\n",
    "liste_df['Hafen'].fillna(liste_df['Hafen'].mode()[0], inplace = True)\n",
    "if Feature_Alleine == 1:\n",
    "    liste_df['Familie'] = liste_df['GeschwPartner'] + liste_df['ElterKind']\n",
    "    liste_df['Alleine'] = 0\n",
    "    liste_df.loc[liste_df['Familie'] == 0, 'Alleine'] = 1\n",
    "    liste_df = liste_df.drop(['Familie', 'GeschwPartner', 'ElterKind'], axis=1)\n",
    "if Feature_Titel == 1:\n",
    "    liste_df['Titel'] = liste_df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    liste_df['Titel'] = liste_df['Titel'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Selten')\n",
    "    liste_df['Titel'] = liste_df['Titel'].replace('Mlle', 'Miss')\n",
    "    liste_df['Titel'] = liste_df['Titel'].replace('Ms', 'Miss')\n",
    "    liste_df['Titel'] = liste_df['Titel'].replace('Mme', 'Mrs')\n",
    "    #liste_df['Titel'] = liste_df['Titel'].fillna(0)\n",
    "liste_df = liste_df.drop(['Name'], axis=1)\n",
    "liste_df['Geschlecht'] = liste_df['Geschlecht'].map( {'Frau': 1, 'Mann': 0} ).astype(int)\n",
    "liste_df = pd.get_dummies(liste_df, sparse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wird der zuvor auf historischen Daten trainierte Klassifizierer auf die neue Personenliste angewandt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Vorhersage = Klassifizierer.predict(liste_df)\n",
    "Vorhersage_proba = Klassifizierer.predict_proba(liste_df)\n",
    "personenliste_df['Lebendig (Vorhersage)'] = Vorhersage\n",
    "personenliste_df['Wahrscheinlichkeit'] = Vorhersage_proba[:, [1]]*100\n",
    "personenliste_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "# Phase 7 – Die Weiterentwicklung: Die fortlaufende Datensammlung\n",
    "### Bei den Recherchen der Nachkommen ergeben sich zusätzliche Informationen, ob die Personen die Titanic-Katastrophe überlebt hatten oder nicht. Diese können den bestehenden Datensatz ergänzen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "# Phase 8 – Die fortlaufende Überprüfung: Die Wartung\n",
    "### Mit hinzukommenden Daten (bzw. Informationen ob weitere Personen überlebt hatten oder nicht) kann das bestehende Modell evaluiert werden. Sollte die Fehlerquote weitaus höher als bei den Testdaten sein, scheinen die Zusammenhänge aus den neuen Datenquellen nicht übereinzustimmen. Beispielsweise könnte es sich bei den neuen Informationen rein um Beschäftigte an Board der Titanic handeln. Hier könnten andere Zusammenhänge hinsichtlich Alter, Geschlecht etc. und der Überlebenswahrscheinlichkeit bestehen. Auch könnten hier neue Titel auftreten, welche wesentliche Informationen beinhalten (z. B. \"Mate\" für Matrosen). "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:tf2] *",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
